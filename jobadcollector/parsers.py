from html.parser import HTMLParser
import urllib.request
from urllib.parse import urlparse
from urllib.parse import quote_plus
import re

class URLGenerator:
    """ Generates URLs based on provided search term for different sites. """
    def Indeed_URL(search_term):
        search_term = search_term.replace(" ", "%20")
        return "http://www.indeed.fi/jobs?as_and=%s&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&radius=50&l=Helsinki&fromage=any&limit=50&sort=date&psf=advsrch" % quote_plus(search_term)
    def Monster_URL(search_term):
        return "http://hae.monster.fi/ty%%C3%%B6paikkoja/?q=%s&cy=fi" % quote_plus(search_term)
    def Duunitori_URL(search_term):
        return "http://duunitori.fi/tyopaikat/?haku=%s&alue=" % quote_plus(search_term)
    


class IndeedParser(HTMLParser):
    """
    HTML parser for Indeed.fi job searches. Saves results in an instance dictionary 
    as {id: [title, url]}, where id is taken from the webpage.
    """
    job = 0
    add = 0
    job_ads = []
    id = ""
    title = ""
    url = ""
    additional = ""

    def __init__(self):
        super(IndeedParser, self).__init__(convert_charrefs=True)

    def save_job_ad(self, id, title, url, additional):
        """
        Saves job ad parsed from html in instance dictionary. 

        id          - Unique id for job ad, either from the website or 
                      generated by the parser.
        title       - Job title.
        url         - URL to the job ad.
        description - Any additional information regarding the job ad.        
        """
        self.job_ads.append({"id" : id,
                             "title" : re.sub("\s{2,}", " ", title.strip()), 
                             "url" : url, 
                             "description" : re.sub("\s{2,}", " ", additional.strip())})

    def get_job_ads(self):
        """
        Returns the object's dictionary of job entries.
        """
        return self.job_ads

    def handle_starttag(self, tag, attrs):
        if (tag == "h2" and ('class', 'jobtitle') in attrs):
            self.job = 1
            for entry in attrs:
                if entry[0] == "id":
                    self.id = entry[1]
        elif (self.job == 1 and tag == "a"):
            for entry in attrs:
                if entry[0] == "href":
                    self.url = "http://www.indeed.fi" + entry[1]
        elif (self.add == 1 and tag == "div" and 
              ('class', "result-link-bar-container") in attrs):
            self.add = 0
            self.save_job_ad(self.id, self.title, self.url, self.additional)
            self.id = ""
            self.title = ""
            self.url = ""
            self.additional = ""

    def handle_endtag(self, tag):
        if (self.job == 1 and tag == "h2"):
            self.add = 1
            self.job = 0

    def handle_data(self, data):
         if (self.job == 1):
            self.title = self.title + " " +  data.strip()
         elif (self.add == 1):
            self.additional = self.additional + " " + data.strip()

    def parse_URL(self, URL):
        url_req = urllib.request.urlopen(URL)
        encoding = url_req.headers.get_content_charset()
        url_req_text = re.sub("\s+", " ", url_req.read().decode(encoding))
        url_req_text = re.sub("(&nbsp;)+", " ", url_req_text)
        self.feed(url_req_text)


class MonsterParser(HTMLParser):
    """
    HTML parser for Monster.fi job searches. Saves results in an object dictionary 
    as {id: [title, url]}, where id is taken from the webpage.
    """
    job = 0
    add = 0
    job_ads = []
    id = ""
    title = ""
    url = ""
    additional = ""

    def __init__(self):
        super(MonsterParser, self).__init__(convert_charrefs=True)

    def save_job_ad(self, id, title, url, additional):
        """
        Saves job ad parsed from html in instance dictionary. 

        id          - Unique id for job ad, either from the website or 
                      generated by the parser.
        title       - Job title.
        url         - URL to the job ad.
        description - Any additional information regarding the job ad.        
        """
        self.job_ads.append({"id" : id,
                             "title" : re.sub("\s{2,}", " ", title.strip()), 
                             "url" : url, 
                             "description" : re.sub("\s{2,}", " ", additional.strip())})

    def get_job_ads(self):
        """Returns the object's dictionary of job entries."""
        return self.job_ads

    def handle_starttag(self, tag, attrs):
        if (self.job != 1 and tag == "div" and ('class', 'jobTitleContainer') in attrs):
            self.job = 1
        elif (self.job != 1 and tag == "div" and ('class', 'companyContainer') in attrs):
            self.add = 1
        elif (self.job != 1 and self.add == 1 and tag == "div" and 
              ('class', 'companyLogo') in attrs):
            self.save_job_ad(self.id, self.title, self.url, self.additional)
            self.add = 0
            self.id = ""
            self.title = ""
            self.url = ""
            self.additional = ""
        elif (self.job == 1 and tag == "a"):
            for entry in attrs:
                if entry[0] == "href":
                    self.url = entry[1].strip()
                elif entry[0] == "name":
                    self.id = entry[1].strip()

    def handle_endtag(self, tag):
        if (self.job == 1 and tag == "div"):
            self.job = 0

    def handle_data(self, data):
         if (self.job == 1):
             self.title = self.title + " " + data.strip()
         elif (self.add == 1):
             self.additional = self.additional + " " + data.strip()

    def parse_URL(self, URL):
        url_req = urllib.request.urlopen(URL)
        encoding = url_req.headers.get_content_charset()
        url_req_text = re.sub("\s+", " ", url_req.read().decode(encoding))
        url_req_text = re.sub("(&nbsp;)+", " ", url_req_text)
        self.feed(url_req_text)

class DuunitoriParser(HTMLParser):
    """
    HTML parser for Duunitori.fi job searches. Saves results in an object dictionary 
    as {id: [title, url]}, where id is taken from the webpage.
    """
    job = 0
    a_data = 0
    title_added = 0
    job_list = 0
    job_ads = []
    id = ""
    title = ""
    url = "" 
    additional = ""
    
    def __init__(self):
        super(DuunitoriParser, self).__init__(convert_charrefs=True)

    def save_job_ad(self, id, title, url, additional):
        """
        Saves job ad parsed from html in instance dictionary. 

        id          - Unique id for job ad, either from the website or 
                      generated by the parser.
        title       - Job title.
        url         - URL to the job ad.
        description - Any additional information regarding the job ad.        
        """
        self.job_ads.append({"id" : id,
                             "title" : re.sub("\s{2,}", " ", title.strip()), 
                             "url" : url, 
                             "description" : re.sub("\s{2,}", " ", additional.strip())})

    def get_job_ads(self):
        """
        Returns the object's dictionary of job entries.
        """
        return self.job_ads

    def handle_starttag(self, tag, attrs):
        if (tag == "div" and ('id', 'jobentry-list') in attrs):
            self.job_list = 1
        elif (self.job_list == 1 and tag == "div" and 
              ('id', 'bottom-pagination') in attrs):
            self.job_list = 0
        elif (self.job_list == 1 and tag == "article" and 
              ('class', 'jobentry-item') in attrs):
            self.job = 1
            for entry in attrs:
                if entry[0] == 'data-id':
                    self.id = entry[1]
        elif (self.job_list == 1 and tag == "a" and self.job == 1 and 
              ('class', 'jobentry-link') in attrs):
            self.a_data = 1
            for entry in attrs:
                if entry[0] == "href":
                    self.url = "http://www.duunitori.fi/" + entry[1].strip()

    def handle_endtag(self, tag):
        if (self.job_list == 1 and tag == "a" and self.a_data == 1):
            self.title_added = 1
            self.a_data = 0 
            self.job = 0
        elif(self.job_list == 1 and self.title_added == 1 and tag == "article"):
            self.save_job_ad(self.id, self.title, self.url, self.additional)
            self.title_added = 0
            self.title = ""
            self.id = ""
            self.url = ""
            self.additional = ""
            
    def handle_data(self, data):
        if (self.job_list == 1 and self.job == 1 and self.a_data == 1):
            self.title = self.title + " " + data.strip()
        elif(self.job_list == 1 and self.title_added == 1):
            self.additional = self.additional + " " + data.strip()

    def parse_URL(self, URL):
        url_req = urllib.request.urlopen(URL)
        encoding = url_req.headers.get_content_charset()
        url_req_text = re.sub("\s+", " ", url_req.read().decode(encoding))
        url_req_text = re.sub("(&nbsp;)+", " ", url_req_text)
        self.feed(url_req_text)